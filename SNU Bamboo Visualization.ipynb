{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Parsed Data for Phrase Modelling\n",
    "\n",
    "Executing bigram and trigram phrase modelling from the parsed sentences using konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/bin/python3.6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "sentences_normalized_filepath = \"bamboo_parsed.txt\"\n",
    "\n",
    "bigram_model_path = 'bigram_model'\n",
    "trigram_model_path = 'trigram_model'\n",
    "\n",
    "bigram_filepath = 'bamboo_bigram.txt'\n",
    "trigram_filepath = 'bamboo_trigram.txt'\n",
    "\n",
    "unigram_sentences = LineSentence(sentences_normalized_filepath)\n",
    "\n",
    "bigram_model = Phrases(unigram_sentences)\n",
    "bigram_model.save(bigram_model_path)\n",
    "\n",
    "with open(bigram_filepath, 'w') as f:\n",
    "        for unigram_sentence in unigram_sentences:\n",
    "            bigram_sentence = bigram_model[unigram_sentence]\n",
    "            f.write(' '.join(bigram_sentence) + '\\n')\n",
    "            \n",
    "bigram_sentences = LineSentence(bigram_filepath)\n",
    "trigram_model = Phrases(bigram_sentences)\n",
    "trigram_model.save(trigram_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the necessary parsed file to be modified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import csv\n",
    "\n",
    "twitter = Okt()\n",
    "\n",
    "results = []\n",
    "\n",
    "data_path = 'posts_data_50.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts(post):\n",
    "    lines = post[0].split(\"\\n\")\n",
    "    for line in lines:\n",
    "        temp_list = twitter.pos(line, norm=True, stem=True)\n",
    "        r = []\n",
    "        for word in temp_list:\n",
    "            if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "                r.append(word[0])\n",
    "        rl = (\" \".join(r)).strip()\n",
    "    return rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path) as f:\n",
    "    data = csv.reader(f, delimiter=',')\n",
    "    for row in data:\n",
    "        results.append(clean_posts(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepping Data for LDA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "lda_filepath = 'lda_data.txt'\n",
    "\n",
    "with open(lda_filepath, 'w') as f:\n",
    "        for review_parsed in results:\n",
    "            unigram_review = review_parsed\n",
    "            bigram_review = bigram_model[unigram_review]\n",
    "            trigram_review = trigram_model[bigram_review]\n",
    "\n",
    "            f.write(' '.join(trigram_review) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Topic Modelling\n",
    "\n",
    "performing LDA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dictionary for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_made = False\n",
    "\n",
    "dict_path = 'dictionary.dict'\n",
    "\n",
    "if dict_made:\n",
    "    dictionary = Dictionary.load(dict_path)\n",
    "else:\n",
    "    reviews_for_lda = word2vec.LineSentence(lda_filepath)\n",
    "    dictionary = Dictionary(reviews_for_lda)\n",
    "    dictionary.filter_extremes(no_below=10, no_above=0.4)\n",
    "    dictionary.compactify()\n",
    "\n",
    "    dictionary.save(dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create corpus for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = 'corpus.mm'\n",
    "\n",
    "def make_bow_corpus(filepath):\n",
    "        \"\"\"\n",
    "        generator function to read in reviews from the file\n",
    "        and output a bag-of-words represention of the text\n",
    "        \"\"\"\n",
    "        for review in LineSentence(filepath):\n",
    "            yield dictionary.doc2bow(review)\n",
    "            \n",
    "MmCorpus.serialize(corpus_path, make_bow_corpus(lda_filepath))\n",
    "\n",
    "review_corpus = MmCorpus(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(review_corpus, num_topics=20, id2word=dictionary,  workers=2)\n",
    "lda.save(lda_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topic(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
